# cohere-example
Test for cohere API on flight cancellation policy.

# Output as below:

Flight Cancellation Policy:

If your flight is canceled, you may be entitled to a full refund or a rebooking on the next available flight. 
Please contact our customer service for assistance. 
In the case of severe weather or other extraordinary circumstances, we may not be able to provide compensation. 
Make sure to check your email for updates regarding your flight status.


Full Response:
id='5cc1b52c-055f-45a9-8c68-2c78c28d9440' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text="The key points of this policy are:\n\n- Flight Cancellation Refund or Rebooking: If a passenger's flight is canceled, they have the option to receive a full refund for their ticket or be rebooked on the next available flight to their destination.\n- Customer Service Assistance: Affected passengers are advised to contact customer service for help and to discuss their preferred option (refund or rebooking).\n- Severe Weather or Extraordinary Circumstances: In cases of severe weather or other events beyond the airline's control (extraordinary circumstances), compensation may not be provided. Examples might include hurricanes, earthquakes, or political unrest.\n- Flight Status Updates: Passengers are advised to check their emails regularly for any updates or changes to their flight status, especially if severe weather or potential disruptions are anticipated.")], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=83.0, output_tokens=159.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=276.0, output_tokens=159.0)) logprobs=None


# Overview on Tokens ðŸª™ used -- High! 

### Token ðŸª™ Usage Example

1. **Input Tokens**: 
   - The flight cancellation policy and the question you sent to the model.
   - Example: If the input text is 83 tokens.

2. **Output Tokens**: 
   - The response generated by the model.
   - Example: If the output text is 190 tokens.

3. **Total Tokens ðŸª™**: 
   - Sum of input and output tokens.
   - Example: Total = 83 (input) + 190 (output) = 273 tokens.

### Summary
- **Input**: 83 tokens
- **Output**: 190 tokens
- **Total**: 273 tokens

This gives you a clear idea of how many tokens were used in the context of the code and its output. If you have any more questions, feel free to ask!


### Updated! Token less than 30:

# OUTPUT

Flight Cancellation Policy:

If your flight is canceled, you may be entitled to a full refund or a rebooking on the next available flight. 
Please contact our customer service for assistance. 
In the case of severe weather or other extraordinary circumstances, we may not be able to provide compensation. 
Make sure to check your email for updates regarding your flight status.


Full Response:
id='c0545ac8-652b-49ec-bd08-48bd5d3f8361' finish_reason='MAX_TOKENS' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='If a flight is canceled, passengers have the option to receive a refund or rebook their flight.')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=27.0, output_tokens=20.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=220.0, output_tokens=20.0)) logprobs=None
No response messages found.

### SUMMARY OF TOKENS ðŸª™

Token Summary
1. Input Tokens: 27 tokens
2. Output Tokens: 20 tokens
3. Total Tokens: 220 tokens (this seems to be the total for the entire session, including previous interactions)

Finish Reason: MAX_TOKENS indicates that the output was limited by the maximum token setting.

* Key Points
- Input: The input text you provided was concise, using only 27 tokens. ðŸª™ðŸª™ #LESS TOKENS USED
- Output: The model generated a brief response of 20 tokens.
- Total Usage: The total token count reflects the cumulative usage, which may include previous prompts and responses.

Summary in 50 Words
To summarize the token usage: You used 27 tokens for the input and received a response of 20 tokens from the model. The total token count for the session was 220 tokens, with the output limited by the maximum token setting, resulting in a concise response.